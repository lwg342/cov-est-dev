\subsection{Global Minimum Variance Portfolio}

We apply the Network Guided Estimator to a portfolio management similar to \cite{ledoit2004HoneyShrunk}. We collect daily return data on SP500 stock from 2004 to 2019 from CRSP, together with daily data on Fama-French 3 factors and the risk free rate. 

Assume that the excess returns follow the following factor model
\begin{equation*}
    Y_{it} = B_{i}'F_{t} + \epsilon_{it}
\end{equation*}
and we assume that \(\Sigma = [E \epsilon_{i} \epsilon_{j}]_{1 \leq i,j\leq N}\) is sparse. 

We do a rolling window analysis, each window consists of an estimation period of 252 days and a testing period of 21 days. In the estimation period, we estimate the factor loadings by linear time series regression of excess return \(Y_{it}\) on \(F_{t}\), hence allowing the betas to vary over time, and find the de-factored excess return by 
\begin{equation*}
    \hat{\epsilon}_{it} = Y_{it} - \hat{B}_{i}'F_{t}
\end{equation*}
and in order to estimate the covariance matrix of \(Y = \pqty{Y_{1}, \dots, Y_{N}}'\), we have, under the assumption that \(\epsilon\)'s are independent of \(F_{t}\), 
\begin{equation*}
    \Sigma_{Y} = B \Sigma_{F} B' + \Sigma_{\epsilon}
\end{equation*}
We replace the factor covariance component by \(\hat{B} \hat{\Sigma}_{F} \hat{B}\), where \(\hat{\Sigma}_{F}\) is the sample covariance of factors in that period, and we estimate \(\Sigma_{\epsilon}\) by the Network Guided Estimator applied to \(\hat{\Sigma}_{\epsilon} = \frac{1}{T} \sum_{t}\hat{\epsilon}_{t} \hat{\epsilon}_{t}'\). 

In order to apply the Network Guided Estimator, we consider two \(G\) matrix that comes from analysts co-coverage:1. IBES: .... 2: Dow Jones: .... 

In order to keep \(G\) sparse and mitigate the noisy observations, we set for IBES, \(G_{ij} = 1\) if firms \((i,j)\) are mentioned more than 18 times, and for Dow Jones data, \(G_{ij} =1\) if firms (i,j) are co-mentioned more than 100 times. With this choice, the total number of links is around 1\textperthousand of the whole network matrix. We select the thresholding parameter using cross-validation with the constraint that the resulting estimate is positvie definite. When the thresholding level becomes higher, the resulting estimate becomes more sparse, in the limit, it'll be a diagonla matrix and p.d., so we keep the thresholding level above the minimum level for the estimate to be p.d. 

After using the data from estimation period to estimate \(\hat{B} ,\hat{\Sigma}_{F}, \hat{\Sigma}_{\epsilon}\), we construct 
\begin{equation*}
    \hat{\Sigma}_{Y} = \hat{B} \hat{\Sigma}_{F} \hat{B}' + \hat{\Sigma}_{\epsilon} 
\end{equation*}
and construct the \textit{global minimum variance} portfolio where weights are given by 
\begin{equation*}
    w = \frac{\hat{\Sigma}_{Y} \mathbf{1}}{\mathbf{1}' \hat{\Sigma}_{Y} \mathbf{1}}
\end{equation*}
where \(\mathbf{1}\) is a conforming vector of ones. We collect the portfolio return over the next 21-day testing period. This conludes one of the rolling windows. Then we move forward 21 days and repeat this exercise. Using 2004- 2014 daily data, we can construct a daily portfolio return from 2005 to 2015, where the portfolio is rebalanced every 21 days. We compute the holding period return of this portfolio and its standard deviation. In autoref{t:4} we show the result together with mean and Sharpe ratio and compare it with global minimum variance portfolio constructed using linear shrinkage and universal thresholding. It's worth mentioning that given we are comparing global minimum variance portfolio, the standard deviation is the relevant indicator of performance.  



